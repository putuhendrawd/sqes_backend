{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, time, requests , signal\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "import rasterio\n",
    "import matplotlib\n",
    "import hvsrpy\n",
    "import pathlib\n",
    "from matplotlib import pyplot as plt\n",
    "from datetime import timedelta\n",
    "from rasterio.transform import from_origin\n",
    "from obspy import UTCDateTime, read_inventory\n",
    "from obspy.clients.fdsn import Client\n",
    "from obspy.signal import PPSD\n",
    "from obspy.imaging.cm import pqlx\n",
    "from obspy.signal.quality_control import MSEEDMetadata\n",
    "from sqes_function import Calculation, Analysis, MySQLPool, Config\n",
    "from datetime import datetime\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "### function list ###\n",
    "# timeout handling function\n",
    "def handle_timeout(signum,frame):\n",
    "    raise TimeoutError\n",
    "\n",
    "# processes rounding function\n",
    "def processes_round(x, base=2):\n",
    "    min_value = 4\n",
    "    max_value = multiprocessing.cpu_count() // 3\n",
    "    rounded_value = base * round(x / base)\n",
    "    if rounded_value < min_value:\n",
    "        return min_value\n",
    "    elif rounded_value > max_value:\n",
    "        return max_value\n",
    "    else:\n",
    "        return rounded_value\n",
    "    \n",
    "# create directory function\n",
    "def create_directory(dir_path):\n",
    "    if not os.path.isdir(dir_path):\n",
    "        os.makedirs(dir_path)\n",
    "        print(f\"{dir_path} created\")\n",
    "    else:\n",
    "        print(f\"{dir_path} exists\")\n",
    "\n",
    "def is_client_connected(client):\n",
    "    try:\n",
    "        # Try querying data to check connectivity\n",
    "        client.get_events(starttime=UTCDateTime(2010,1,1,0,0,0), endtime=UTCDateTime(2010,1,2,0,1,0))\n",
    "        return True\n",
    "    except (requests.ConnectionError, requests.Timeout):\n",
    "        return False\n",
    "\n",
    "# download data function\n",
    "def DownloadData(client, sta, time0, time1, c):\n",
    "    signal.signal(signal.SIGALRM, handle_timeout)\n",
    "    signal.alarm(600)\n",
    "    try:\n",
    "        channel_codes = [f\"SH{c}\", f\"BH{c}\", f\"HH{c}\"] # [f\"SH{c}\", f\"BH{c}\", f\"HH{c}\"]\n",
    "        for channel_code in channel_codes:\n",
    "            network = \"*\" if channel_code == f\"BH{c}\" else \"IA\"\n",
    "            try:\n",
    "                st = client.get_waveforms(network, sta, \"*\", channel_code, time0, time1)\n",
    "                if st.count() > 0:\n",
    "                    try:\n",
    "                        inv = read_inventory(f\"https://geof.bmkg.go.id/fdsnws/station/1/query?station={sta}&level=response&nodata=404\")\n",
    "                        return st, inv\n",
    "                    except:\n",
    "                        return st, None\n",
    "            except:\n",
    "                continue\n",
    "    except TimeoutError:\n",
    "        print(f\"!! {sta} download timeout!\")\n",
    "        return \"No Data\", None\n",
    "    # if all except\n",
    "    return \"No Data\", None\n",
    "\n",
    "def time_check(st):\n",
    "\tendt = min([st[0].stats.endtime, st[1].stats.endtime, st[2].stats.endtime])\n",
    "\tstartt = max([st[0].stats.starttime, st[1].stats.starttime, st[2].stats.starttime])\n",
    "\treturn endt, startt\n",
    "\n",
    "def get_tif_values(src, lat, lon):\n",
    "    keys = [\"geology\",\"vs30\",\"photovoltaic\"]\n",
    "\n",
    "    values = {}\n",
    "    for key, src in zip(keys,src):\n",
    "        try:\n",
    "            z = src.read()[0]\n",
    "            idx = src.index(lon, lat) \n",
    "            # Read the value at the specified location \n",
    "            values[key] = float(z[idx])\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            values[key] = None\n",
    "    return values\n",
    "\n",
    "def plot_psd(psds,periods,NHNM,NLNM,outfile,sta,label):\n",
    "\tfor i in range(len(psds)): \n",
    "\t\tplt.plot(periods[i],psds[i],linewidth=1)\n",
    "\tplt.plot(periods[i], NHNM, c='black', linewidth=2)\n",
    "\tplt.plot(periods[i], NLNM, c='black', linewidth=2)\n",
    "\tplt.xscale('log')\n",
    "\tplt.grid(True, which=\"both\");plt.xlim([0.1,100])\n",
    "\tplt.legend(label, loc='upper right')\n",
    "\tplt.xlabel('Periods (s)')\n",
    "\tplt.ylabel(r'Power [$10log_{10}(\\frac{m^2/s^4}{hz}$)][dB]')\n",
    "\tplt.title(f\"{sta} Station\")\n",
    "\tplt.savefig(outfile)\n",
    "\tplt.clf()\n",
    "\n",
    "def gval_to_geo(gval):\n",
    "    if gval == 1:\n",
    "        return \"Sedimen Muda\"\n",
    "    elif gval == 2:\n",
    "        return \"Sedimen Periode Quarter\"\n",
    "    elif gval == 3:\n",
    "        return \"Batuan Gunung Api Muda\"\n",
    "    elif gval == 4:\n",
    "        return \"Batuan/Sedimen Tua Periode Tersier\"\n",
    "    else:\n",
    "        return \"-\"\n",
    "    \n",
    "def vs30_to_ket_vval(vs30):\n",
    "    if vs30 > 1500:\n",
    "        return \"Batuan\", 4\n",
    "    elif vs30 > 760 and vs30 <= 1500:\n",
    "        return \"Sangat Keras\", 4\n",
    "    elif vs30 > 360 and vs30 <= 760:\n",
    "        return \"Keras\", 3\n",
    "    elif vs30 > 180 and vs30 <= 360:\n",
    "        return \"Sedang\", 2\n",
    "    elif vs30 <= 180:\n",
    "        return \"Lunak\", 1\n",
    "    \n",
    "def pvout_to_ket_pval(pvout):\n",
    "    if pvout > 1530 :\n",
    "        return \"Sangat Baik\", 4\n",
    "    elif pvout <= 1530 and pvout > 1400 :\n",
    "        return \"Baik\", 3\n",
    "    elif pvout <= 1400 and pvout > 1000:\n",
    "        return \"Cukup\", 2\n",
    "    elif pvout <= 1000:\n",
    "        return \"Kurang\", 1\n",
    "    else:\n",
    "        return \"-\", 0\n",
    "\n",
    "def hvsr_to_ket_hval(t0):\n",
    "    if t0 > 0.6:\n",
    "        return \"Lunak\", 1\n",
    "    elif t0 > 0.4 and t0 <= 0.6:\n",
    "        return \"Sedang\", 2\n",
    "    elif t0 > 0.2 and t0 <= 0.4:\n",
    "        return \"Keras\", 3\n",
    "    elif t0 <= 0.2:\n",
    "        return \"Batuan\", 4\n",
    "\n",
    "def psd_to_ket_psdval(perc_psd):\n",
    "    if perc_psd > 85:\n",
    "        return \"Sangat Baik\", 4\n",
    "    elif perc_psd > 70 and perc_psd <= 85:\n",
    "        return \"Baik\", 3\n",
    "    elif perc_psd > 50 and perc_psd <= 70:\n",
    "        return \"Cukup\", 2\n",
    "    elif perc_psd <= 50:\n",
    "        return \"Kurang\", 1\n",
    "\n",
    "def nilai_to_ket(nilai):\n",
    "    if nilai >= 90:\n",
    "        return \"Very Good\"\n",
    "    elif nilai < 90 and nilai >= 75:\n",
    "        return \"Good\"\n",
    "    elif nilai <75 and nilai >= 50:\n",
    "        return \"Fair\"\n",
    "    else:\n",
    "        return \"Poor\"\n",
    "### function list end ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_start = datetime.now()\n",
    "\n",
    "## load credentials and config\n",
    "try:\n",
    "    basic_config = Config.load_config(section='basic')\n",
    "    client_credentials = Config.load_config(section='client')\n",
    "    db_credentials = Config.load_config(section=basic_config['use_database'])\n",
    "    \n",
    "except:\n",
    "    print(f\"!! client/db_credentials not found\")\n",
    "    dt_end = datetime.now()\n",
    "    print(f\"running end at {dt_end}\", flush=True)\n",
    "    print(f\"{sys.argv[0]} Running Complete ({dt_end-dt_start})\", flush=True)\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load tif\n",
    "tif_folder = \"/home/geo2sqes/putu_dev/sqes_backend/files/spk_site\"\n",
    "geology_tif = \"geology.tif\"\n",
    "vs30_tif = \"vs30.tif\"\n",
    "pvout_tif = \"pvout.tif\"\n",
    "\n",
    "geology_src = rasterio.open(os.path.join(tif_folder,geology_tif))\n",
    "vs30_src = rasterio.open(os.path.join(tif_folder,vs30_tif))\n",
    "pvout_src = rasterio.open(os.path.join(tif_folder,pvout_tif))\n",
    "\n",
    "src = [geology_src, vs30_src, pvout_src]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load db\n",
    "mysql_pool = MySQLPool(**db_credentials)\n",
    "\n",
    "# load client\n",
    "client = Client(client_credentials['url'],user=client_credentials['user'],password=client_credentials['password'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_query_a = f\"SELECT kode_sensor,lat_sensor,lon_sensor FROM tb_slmon\"\n",
    "tb_slmon = mysql_pool.execute(db_query_a)\n",
    "# ONLY RUN BELOW IF U WANT TO FILTER STATION \n",
    "# Filter list\n",
    "filter_list = ['KAKKI']\n",
    "# Filtering the data\n",
    "tb_slmon = [item for item in tb_slmon if item[0] in filter_list]\n",
    "update_query = \"\"\"\n",
    "UPDATE tb_slmon\n",
    "SET geo = %s, vs30 = %s, photo = %s, hvsr = %s, psd = %s, nilai = %s, keterangan2 = %s, gval = %s, vval = %s, pval = %s, hval = %s, psdval = %s \n",
    "WHERE kode_sensor = %s;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KAKKI 4.0 369.13006591796875 1307.9599609375\n",
      "KAKKI,Batuan/Sedimen Tua Periode Tersier,Keras,Cukup,1.19,73.96,75,Good,4,3,2,1,3\n"
     ]
    }
   ],
   "source": [
    "for data in tb_slmon[:1]:\n",
    "    # load and config\n",
    "    station = data[0]\n",
    "    psd_outfile = os.path.join(basic_config['outputqcstationpsd'],f\"{station}_PSD.png\")\n",
    "    mseed_outfile = os.path.join(basic_config['outputqcstationmseed'],f\"{station}.mseed\")\n",
    "    hvsr_outfile = os.path.join(basic_config['outputqcstationhvsr'],f\"{station}_HVSR.png\")\n",
    "    # load tif data\n",
    "    tiff_value = get_tif_values(src, float(data[1]), float(data[2]))\n",
    "    print(station, tiff_value['geology'], tiff_value['vs30'], tiff_value['photovoltaic'])\n",
    "    # load stream and inventory\n",
    "    t1=UTCDateTime(\"20240101\")\n",
    "    t2=t1+timedelta(hours=2)\n",
    "    st, inv = DownloadData(client,station,t1,t2,\"*\")\n",
    "    # processing psd\n",
    "    psds=[];periods=[];label=[];perc_psd=[]\n",
    "    for tr in st:\n",
    "        fs = tr.stats.sampling_rate\n",
    "        label.append(tr.stats.channel)\n",
    "        ppsd = PPSD(tr.stats, metadata=inv)\n",
    "        ppsd.add(tr)\n",
    "        period, psd = ppsd.get_percentile()\n",
    "        ind = period <= 100\n",
    "        period = period[ind]\n",
    "        psd = psd[ind]\n",
    "        powers = sorted(range(-190,-90+1), reverse=True)\n",
    "        NHNM, NLNM, PInd = Calculation.get_models(period,powers)\n",
    "        period = period[PInd]\n",
    "        psd = psd[PInd]\n",
    "        pctH, pctL=Calculation.pct_model(psd,NHNM,NLNM)\n",
    "        total_pctH_pctL = pctH+pctL\n",
    "        # total PPSDS inside Model\n",
    "        perc = float((len(psd)-total_pctH_pctL)/len(psd))*100\n",
    "        psds.append(psd);periods.append(period)\n",
    "        perc_psd.append(perc)\n",
    "        plot_psd(psds,periods,NHNM,NLNM,psd_outfile,station,label)\n",
    "    # pre-processing hvsr\n",
    "    endt, startt = time_check(st)\n",
    "    st.trim(startt, endt)\n",
    "    st.write(mseed_outfile)\n",
    "    fs = st[0].stats.sampling_rate\n",
    "    high_pass_freq_filter = float(fs/2)-0.1\n",
    "    # processing hvsr\n",
    "    ## input data\n",
    "    fnames = [[mseed_outfile]]\n",
    "    # print(f\"Number of recordings: {len(fnames)}\")\n",
    "    for fname_set in fnames:\n",
    "        for file in fname_set:\n",
    "            if not pathlib.Path(file).exists():\n",
    "                raise FileNotFoundError(f\"file {file} not found; check spelling.\")\n",
    "    # print(\"All files exist.\")\n",
    "    # preprocessing settings\n",
    "    preprocessing_settings = hvsrpy.settings.HvsrPreProcessingSettings()\n",
    "    preprocessing_settings.detrend = \"linear\"\n",
    "    preprocessing_settings.window_length_in_seconds = 60\n",
    "    preprocessing_settings.orient_to_degrees_from_north = 0.0\n",
    "    preprocessing_settings.filter_corner_frequencies_in_hz = (0.5, high_pass_freq_filter)\n",
    "    preprocessing_settings.ignore_dissimilar_time_step_warning = False\n",
    "    # print(\"Preprocessing Summary\")\n",
    "    # print(\"-\"*60)\n",
    "    # preprocessing_settings.psummary()\n",
    "    # processing settings\n",
    "    processing_settings = hvsrpy.settings.HvsrTraditionalProcessingSettings()\n",
    "    processing_settings.window_type_and_width = (\"tukey\", 0.2)\n",
    "    processing_settings.smoothing=dict(operator=\"konno_and_ohmachi\",\n",
    "                                    bandwidth=40,\n",
    "                                    center_frequencies_in_hz=np.geomspace(0.2, 20, 200))\n",
    "    processing_settings.method_to_combine_horizontals = \"geometric_mean\"\n",
    "    processing_settings.handle_dissimilar_time_steps_by = \"frequency_domain_resampling\"\n",
    "    # print(\"Processing Summary\")\n",
    "    # print(\"-\"*60)\n",
    "    # processing_settings.psummary()\n",
    "    # calculate\n",
    "    srecords = hvsrpy.read(fnames)\n",
    "    srecords = hvsrpy.preprocess(srecords, preprocessing_settings)\n",
    "    hvsr = hvsrpy.process(srecords, processing_settings)\n",
    "    search_range_in_hz = (0.5, high_pass_freq_filter)\n",
    "    verbose = 1\n",
    "    hvsr.update_peaks_bounded(search_range_in_hz=search_range_in_hz)\n",
    "    # print(\"\\nStatistical Summary:\")\n",
    "    # print(\"-\"*20)\n",
    "    # hvsrpy.summarize_hvsr_statistics(hvsr)\n",
    "    fig, ax = hvsrpy.plot_single_panel_hvsr_curves(hvsr)\n",
    "    ax.get_legend().remove()\n",
    "    # ax.legend(loc=\"center left\", bbox_to_anchor=(1, 0.5))\n",
    "    fig.savefig(hvsr_outfile)\n",
    "    hvsr_f0, hvsr_a0 = hvsr.mean_curve_peak()\n",
    "    hvsr_f0 = round(hvsr_f0,2)\n",
    "    hvsr_t0 = round(1/hvsr_f0,2)\n",
    "    # setup output\n",
    "    gval = int(tiff_value['geology'])\n",
    "    geo = gval_to_geo(tiff_value['geology'])\n",
    "    vs30,vval = vs30_to_ket_vval(tiff_value['vs30'])\n",
    "    photo,pval = pvout_to_ket_pval(tiff_value['photovoltaic'])\n",
    "    _, hval = hvsr_to_ket_hval(hvsr_t0)\n",
    "    mean_psd = round(np.mean(perc_psd),2)\n",
    "    _, psdval = psd_to_ket_psdval(mean_psd)\n",
    "    # buat penilaian berdasar bobot\n",
    "    nilai = hval + (12)*psdval + 4*gval + 6*vval + 2*pval\n",
    "    keterangan2 = nilai_to_ket(nilai)\n",
    "    print(station,geo,vs30,photo,hvsr_t0,mean_psd,nilai,keterangan2,gval,vval,pval,hval,psdval,sep=\",\")\n",
    "    # update DB\n",
    "    update_query_values = (geo,vs30,photo,hvsr_t0,mean_psd,nilai,keterangan2,gval,vval,pval,hval,psdval,station)\n",
    "    mysql_pool.execute(sql=update_query,args=update_query_values,commit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running end at 2025-01-28 10:53:24.060415\n"
     ]
    }
   ],
   "source": [
    "dt_end = datetime.now()\n",
    "print(f\"running end at {dt_end}\", flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sqes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
